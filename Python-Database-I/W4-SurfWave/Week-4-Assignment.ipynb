{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping HTML Data with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pr4e.dr-chuck.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program to use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome Dibakar Sigdel from Using Python to Access Web Data\n",
    "\n",
    "Scraping Numbers from HTML using BeautifulSoup In this assignment you will write a Python program similar to http://www.pythonlearn.com/code/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the sum for your testing and the other is the actual data you need to process for the assignment.\n",
    "\n",
    "* Sample data: http://python-data.dr-chuck.net/comments_42.html (Sum=2553)\n",
    "\n",
    "* Actual data: http://python-data.dr-chuck.net/comments_199858.html (Sum ends with 21)\n",
    "\n",
    "You do not need to save these files to your folder since your program will read the data directly from the URL. Note: Each student will have a distinct data url for the assignment - so only use your own data url for analysis.\n",
    "Data Format\n",
    "The file is a table of names and comment counts. You can ignore most of the data in the file except for lines like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\\n<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\\n<tr><td>Hubert</td><td><span class=\"comments\">87</span></td></tr>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\n",
    "<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\n",
    "<tr><td>Hubert</td><td><span class=\"comments\">87</span></td></tr>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are to find all the <span> tags in the file and pull out the numbers from the tag and sum the numbers.\n",
    "Look at the sample code provided. It shows how to find all of a certain kind of tag, loop through the tags and extract the various aspects of the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"...\\n# Retrieve all of the anchor tags\\ntags = soup('a')\\nfor tag in tags:\\n   # Look at the parts of a tag\\n   print 'TAG:',tag\\n   print 'URL:',tag.get('href', None)\\n   print 'Contents:',tag.contents[0]\\n   print 'Attrs:',tag.attrs\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''...\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "   # Look at the parts of a tag\n",
    "   print 'TAG:',tag\n",
    "   print 'URL:',tag.get('href', None)\n",
    "   print 'Contents:',tag.contents[0]\n",
    "   print 'Attrs:',tag.attrs'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to adjust this code to look for span tags and pull out the text content of the span tag, convert them to integers and add them up to complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program -  test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "import urllib\n",
    "from BeautifulSoup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://python-data.dr-chuck.net/comments_42.html\"\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "tags = soup('span')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cnt = []\n",
    "for tag in tags:\n",
    "    # Look at the parts of a tag\n",
    "    # print 'TAG:',tag\n",
    "    # print 'URL:',tag.get('href', None)\n",
    "    #print 'Contents:',tag.contents[0]\n",
    "    Cnt.append(tag.contents[0])\n",
    "    #print 'Attrs:',tag.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'100', u'97', u'87', u'86', u'86', u'78', u'75', u'74', u'72', u'72']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cnt[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeautifulSoup.NavigableString"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Cnt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = []\n",
    "import re\n",
    "for k in range(len(Cnt)):\n",
    "    #Cnt[k] = Cnt[k].rstrip()\n",
    "    t =   re.findall('([0-9]+)',str(Cnt[k]))\n",
    "    T.append(t[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100', '97', '87', '86', '86', '78', '75', '74', '72', '72']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2482"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TT= []\n",
    "for c in T:\n",
    "    TT.append(int(float(c)))\n",
    "sum(TT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Assmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "import urllib\n",
    "from BeautifulSoup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://python-data.dr-chuck.net/comments_199858.html\"\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "tags = soup('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ht = []\n",
    "for tag in tags:\n",
    "    Ht.append(tag.contents[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'100', u'99', u'93', u'93', u'92', u'91', u'90', u'88', u'86', u'83']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ht[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = []\n",
    "import re\n",
    "for k in range(len(Cnt)):\n",
    "    t =   re.findall('([0-9]+)',str(Ht[k]))\n",
    "    H.append(int(float(t[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2488"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Following Links in HTML Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program that expands on http://www.pythonlearn.com/code/urllinks.py. The program will use urllib to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position from the top and follow that link, repeat the process a number of times, and report the last name you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome Dibakar Sigdel from Using Python to Access Web Data\n",
    "\n",
    "* Following Links in Python\n",
    "\n",
    "In this assignment you will write a Python program that expands on http://www.pythonlearn.com/code/urllinks.py. The program will use urllib to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position relative to the first name in the list, follow that link and repeat the process a number of times and report the last name you find.\n",
    "\n",
    "We provide two files for this assignment. One is a sample file where we give you the name for your testing and the other is the actual data you need to process for the assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*  Sample problem: Start at https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fikret.html\n",
    "    Find the link at position 3 (the first name is 1). Follow that link. Repeat this process 4 times. The answer is the last name that you retrieve.\n",
    "    Sequence of names: Fikret Montgomery Mhairade Butchi Anayah\n",
    "    Last name in sequence: Anayah\n",
    "        \n",
    "*  Actual problem: Start at: https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fezaan.html\n",
    "    Find the link at position 18 (the first name is 1). Follow that link. Repeat this process 7 times. The answer is the last name that you retrieve.\n",
    "    Hint: The first character of the name of the last page that you will load is: R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Strategy\n",
    "\n",
    "The web pages tweak the height between the links and hide the page after a few seconds to make it difficult for you to do the assignment without writing a Python program. But frankly with a little effort and patience you can overcome these attempts to make it a little harder to complete the assignment without writing a Python program. But that is not the point. The point is to write a clever Python program to solve the program.\n",
    "\n",
    "* Sample execution\n",
    "\n",
    "Here is a sample execution of a solution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fikret.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fikret.html\"\n",
    "print 'Retrieving', url\n",
    "\n",
    "scontext = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n",
    "uh = urllib.urlopen(url, context=scontext)\n",
    "html = uh.read()\n",
    "#html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "tags = soup('a')\n",
    "url =  tags[3].get('href',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url3 =  tags[3].get('href',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Owain.html'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run in cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrive(url):\n",
    "    print 'Retrieving', url\n",
    "    scontext = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n",
    "    uh = urllib.urlopen(url, context=scontext)\n",
    "    html = uh.read()\n",
    "    #html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    tags = soup('a')\n",
    "    new_url =  tags[2].get('href',None)\n",
    "    return new_url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fikret.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Montgomery.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Mhairade.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Butchi.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Anayah.html\n"
     ]
    }
   ],
   "source": [
    "url = \"https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fikret.html\"\n",
    "for k in range(5):\n",
    "    new_url = retrive(url)\n",
    "    url = new_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_retrive(url):\n",
    "    print 'Retrieving', url\n",
    "    scontext = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n",
    "    uh = urllib.urlopen(url, context=scontext)\n",
    "    html = uh.read()\n",
    "    #html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    tags = soup('a')\n",
    "    new_url =  tags[17].get('href',None)\n",
    "    return new_url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fezaan.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Coco.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Vincenzo.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Mila.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Kogan.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Kathryn.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Kiya.html\n",
      "Retrieving https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Raegan.html\n"
     ]
    }
   ],
   "source": [
    "url = \"https://pr4e.dr-chuck.com/tsugi/mod/python-data/data/known_by_Fezaan.html\"\n",
    "for k in range(8):\n",
    "    new_url = new_retrive(url)\n",
    "    url = new_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
